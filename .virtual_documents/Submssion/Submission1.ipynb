import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.multioutput import MultiOutputRegressor
from sklearn.preprocessing import StandardScaler, PowerTransformer,QuantileTransformer
from sklearn.model_selection import GridSearchCV, cross_val_score
from catboost import CatBoostRegressor,Pool


import os
import pandas as pd

# Construct the path
base_path = os.path.join("/", "Volumes", "Extreme SSD", "ShellAi")

test_path = os.path.join(base_path, "test.csv")

# Load the CSV files
test_df = pd.read_csv(test_path)


print("Expected targets:", targets)
print("Actual test_df columns:", test_df.columns.tolist())


# Creating  weighted columns
base_features = [col for col in test_df.columns if col not in [f"BlendProperty{i}" for i in range(1, 11)]]
targets = [f"BlendProperty{i}" for i in range(1, 11)]
weighted_data = {}
for i in range(1, 6):
    for j in range(1, 11):
        prop_col = f"Component{i}_Property{j}"
        frac_col = f"Component{i}_fraction"
        weighted_col = f"Weighted_Component{i}_Property{j}"
        weighted_data[weighted_col] = test_df[prop_col] * test_df[frac_col]

# Combine
data_with_weighted = pd.concat([test_df[base_features], pd.DataFrame(weighted_data)], axis=1)
data_with_weighted = data_with_weighted.copy()  # De-fragmented copy



