


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Set style
plt.style.use('seaborn-v0_8')
sns.set_palette('husl')
%matplotlib inline


# Load the dataset
df = pd.read_csv('train.csv')
print(f"Dataset shape: {df.shape}")
print(f"Dataset size: {df.size} values")
print(f"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")





# Basic info about the dataset
print("Dataset Info:")
print(f"Number of rows: {len(df)}")
print(f"Number of columns: {len(df.columns)}")
print(f"Data types: {df.dtypes.value_counts()}")
print("\nFirst 5 rows:")
df.head()


# Check for missing values
missing_values = df.isnull().sum()
print(f"Missing values found: {missing_values.sum()}")
if missing_values.sum() > 0:
    print("Columns with missing values:")
    print(missing_values[missing_values > 0])
else:
    print("No missing values found in the dataset!")


# Basic statistical summary
print("Basic Statistical Summary:")
df.describe()





# Extract component fractions
fraction_cols = [col for col in df.columns if 'fraction' in col]
print(f"Component fraction columns: {fraction_cols}")

# Check if fractions sum to 1
fraction_sums = df[fraction_cols].sum(axis=1)
print(f"\nFraction sums statistics:")
print(f"Mean: {fraction_sums.mean():.4f}")
print(f"Std: {fraction_sums.std():.4f}")
print(f"Min: {fraction_sums.min():.4f}")
print(f"Max: {fraction_sums.max():.4f}")

# Plot fraction distributions
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.ravel()

for i, col in enumerate(fraction_cols):
    axes[i].hist(df[col], bins=30, alpha=0.7, edgecolor='black')
    axes[i].set_title(f'{col}')
    axes[i].set_xlabel('Fraction')
    axes[i].set_ylabel('Frequency')

# Plot sum of fractions
axes[5].hist(fraction_sums, bins=30, alpha=0.7, edgecolor='black', color='red')
axes[5].set_title('Sum of All Fractions')
axes[5].set_xlabel('Sum')
axes[5].set_ylabel('Frequency')
axes[5].axvline(x=1, color='black', linestyle='--', label='Expected sum=1')
axes[5].legend()

plt.tight_layout()
plt.show()


# Correlation between component fractions
plt.figure(figsize=(8, 6))
sns.heatmap(df[fraction_cols].corr(), annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5)
plt.title('Correlation Matrix: Component Fractions')
plt.show()

# Pairplot of fractions
g = sns.pairplot(df[fraction_cols], diag_kind='hist', corner=True)
g.fig.suptitle('Component Fractions Pairplot', y=1.02)
plt.show()





# Extract component properties for each component
components = ['Component1', 'Component2', 'Component3', 'Component4', 'Component5']
property_cols = {}

for comp in components:
    property_cols[comp] = [col for col in df.columns if comp in col and 'Property' in col]
    print(f"{comp} properties: {len(property_cols[comp])} columns")

# Statistics for each component's properties
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.ravel()

for i, comp in enumerate(components):
    comp_data = df[property_cols[comp]]
    
    # Box plot for the component
    axes[i].boxplot([comp_data[col] for col in comp_data.columns], 
                   labels=[f'P{j+1}' for j in range(len(comp_data.columns))])
    axes[i].set_title(f'{comp} Properties Distribution')
    axes[i].set_ylabel('Property Value')
    axes[i].set_xlabel('Property Number')
    axes[i].grid(True, alpha=0.3)

# Remove the extra subplot
fig.delaxes(axes[5])
plt.tight_layout()
plt.show()


# Statistical summary for each property across components
property_stats = pd.DataFrame()

for i in range(1, 11):  # Properties 1-10
    prop_cols = [f'Component{j}_Property{i}' for j in range(1, 6)]
    
    stats_row = {
        'Property': f'Property{i}',
        'Mean': df[prop_cols].mean().mean(),
        'Std': df[prop_cols].std().mean(),
        'Min': df[prop_cols].min().min(),
        'Max': df[prop_cols].max().max(),
        'Range': df[prop_cols].max().max() - df[prop_cols].min().min()
    }
    property_stats = pd.concat([property_stats, pd.DataFrame([stats_row])], ignore_index=True)

print("Statistics across all components for each property:")
property_stats





# Extract blend properties
blend_cols = [col for col in df.columns if 'BlendProperty' in col]
print(f"Blend property columns ({len(blend_cols)}): {blend_cols}")

# Distribution of blend properties
fig, axes = plt.subplots(2, 5, figsize=(20, 10))
axes = axes.ravel()

for i, col in enumerate(blend_cols):
    axes[i].hist(df[col], bins=30, alpha=0.7, edgecolor='black')
    axes[i].set_title(f'{col}')
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')
    
    # Add mean line
    mean_val = df[col].mean()
    axes[i].axvline(x=mean_val, color='red', linestyle='--', 
                   label=f'Mean: {mean_val:.2f}')
    axes[i].legend()

plt.tight_layout()
plt.show()

# Statistical summary for blend properties
print("\nBlend Properties Statistical Summary:")
df[blend_cols].describe()



# Correlation matrix for blend properties
plt.figure(figsize=(12, 10))
blend_corr = df[blend_cols].corr()
sns.heatmap(blend_corr, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, fmt='.2f')
plt.title('Correlation Matrix: Blend Properties')
plt.show()

# Find highly correlated pairs
corr_pairs = []
for i in range(len(blend_cols)):
    for j in range(i+1, len(blend_cols)):
        corr_val = blend_corr.iloc[i, j]
        if abs(corr_val) > 0.5:  # Threshold for high correlation
            corr_pairs.append((blend_cols[i], blend_cols[j], corr_val))

if corr_pairs:
    print("\nHighly correlated blend property pairs (|r| > 0.5):")
    for prop1, prop2, corr in corr_pairs:
        print(f"{prop1} vs {prop2}: {corr:.3f}")
else:
    print("\nNo highly correlated blend property pairs found.")





# Analyze relationship between component fractions and blend properties
print("Correlation between Component Fractions and Blend Properties:")

fraction_blend_corr = df[fraction_cols + blend_cols].corr().loc[fraction_cols, blend_cols]

plt.figure(figsize=(12, 6))
sns.heatmap(fraction_blend_corr, annot=True, cmap='coolwarm', center=0,
            linewidths=0.5, fmt='.2f')
plt.title('Correlation: Component Fractions vs Blend Properties')
plt.ylabel('Component Fractions')
plt.xlabel('Blend Properties')
plt.show()

# Find strongest correlations
strong_corrs = []
for frac in fraction_cols:
    for blend in blend_cols:
        corr_val = fraction_blend_corr.loc[frac, blend]
        if abs(corr_val) > 0.3:  # Threshold for moderate correlation
            strong_corrs.append((frac, blend, corr_val))

if strong_corrs:
    print("\nStrongest correlations between fractions and blend properties (|r| > 0.3):")
    for frac, blend, corr in sorted(strong_corrs, key=lambda x: abs(x[2]), reverse=True):
        print(f"{frac} -> {blend}: {corr:.3f}")
else:
    print("\nNo strong correlations found between fractions and blend properties.")





# Detect outliers using IQR method
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]

# Check outliers in blend properties
outlier_counts = {}
for col in blend_cols:
    outliers = detect_outliers_iqr(df, col)
    outlier_counts[col] = len(outliers)

# Plot outlier counts
plt.figure(figsize=(12, 6))
plt.bar(range(len(outlier_counts)), list(outlier_counts.values()))
plt.xticks(range(len(outlier_counts)), list(outlier_counts.keys()), rotation=45)
plt.title('Number of Outliers per Blend Property (IQR Method)')
plt.ylabel('Number of Outliers')
plt.tight_layout()
plt.show()

print("Outlier summary:")
for prop, count in outlier_counts.items():
    percentage = (count / len(df)) * 100
    print(f"{prop}: {count} outliers ({percentage:.1f}%)")





# Data quality summary
print("=== DATA QUALITY ASSESSMENT ===")
print(f"\n1. DATASET SIZE:")
print(f"   - Rows: {len(df):,}")
print(f"   - Columns: {len(df.columns)}")
print(f"   - Total values: {df.size:,}")

print(f"\n2. MISSING VALUES:")
missing_count = df.isnull().sum().sum()
print(f"   - Total missing: {missing_count}")
print(f"   - Percentage: {(missing_count/df.size)*100:.2f}%")

print(f"\n3. DATA TYPES:")
for dtype, count in df.dtypes.value_counts().items():
    print(f"   - {dtype}: {count} columns")

print(f"\n4. COMPONENT FRACTIONS:")
fraction_sums = df[fraction_cols].sum(axis=1)
valid_fractions = ((fraction_sums >= 0.99) & (fraction_sums <= 1.01)).sum()
print(f"   - Valid fraction sums (0.99-1.01): {valid_fractions}/{len(df)} ({(valid_fractions/len(df))*100:.1f}%)")

print(f"\n5. OUTLIERS (using IQR method):")
total_outliers = sum(outlier_counts.values())
print(f"   - Total outlier instances: {total_outliers}")
print(f"   - Percentage of data points: {(total_outliers/(len(df)*len(blend_cols)))*100:.1f}%")

print(f"\n6. VALUE RANGES:")
print(f"   - Component fractions: {df[fraction_cols].min().min():.3f} to {df[fraction_cols].max().max():.3f}")
print(f"   - Blend properties: {df[blend_cols].min().min():.3f} to {df[blend_cols].max().max():.3f}")

print(f"\n=== SUMMARY ===")
print(f"The dataset appears to be of high quality with:")
print(f"- No missing values")
print(f"- Consistent data types (all numeric)")
print(f"- Valid component fractions that sum to approximately 1")
print(f"- Reasonable value ranges for all features")
print(f"- Manageable number of outliers")



